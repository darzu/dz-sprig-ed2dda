WebGL
  https://twgljs.org // tiny layer over webgl
  https://twgljs.org/examples/twgl-cube.html
  https://twgljs.org/examples/webgl-cube.html
  https://github.com/pmndrs/react-three-fiber
  https://enable3d.io (three.js, ammo.js, capacitor.js, phaser, )
  https://github.com/tamani-coding/enable3d-physics-examples

Three.js:
  https://threejs.org
  https://www.npmtrends.com/babylonjs-vs-three


WebGL learning:
  https://games.greggman.com/game/webgl-3d-cameras/
  https://webglfundamentals.org/webgl/lessons/webgl-3d-camera.html
  https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_best_practices
  https://www.tutorialspoint.com/webgl/webgl_interactive_cube.htm

Babylon:
  https://www.babylonjs.com
  https://playground.babylonjs.com
  https://nme.babylonjs.com // material editor (flow based)
  https://github.com/BabylonJS/SummerFestival
  https://doc.babylonjs.com/guidedLearning/createAGame
  https://babylonjs.medium.com/from-unity-to-babylon-js-how-is-the-journey-c71f79482aa3
  https://news.ycombinator.com/from?site=babylonjs.com

Three.js tutorial:
  https://www.youtube.com/watch?v=cp-H_6VODko

HAXE:
  http://babylonhx.com
  https://haxe.org/use-cases/games/
    Northgard, Dead Cells, "Papers, Please", Rymdkapsel
  https://github.com/armory3d

Multi-platform:
  https://github.com/expo/expo/tree/master/packages/expo-gl#expo-gl

PlayCanvas:
  https://playcanvas.com
  praise: https://news.ycombinator.com/item?id=27050731
  https://news.ycombinator.com/from?site=playcanvas.com
  https://blog.playcanvas.com/a-multiplayer-3rd-person-shooter-in-html5/

Unity Tiny:
  https://unity.com/solutions/instant-games
  https://forum.unity.com/threads/project-tiny-0-32-preview-is-available-ui-new-skinned-mesh-renderer-blendshape-sample.1045204/
  https://tiny.vision/demos/Tiny3D/Wasm/Tiny3D.html (needs Chrome or Safari Preview)
  https://github.com/Unity-Technologies/ProjectTinySamples/tree/master/Tiny3D
  (OLD!) https://docs.unity3d.com/Packages/com.unity.tiny@0.13/manual/scripting-systems.html
  (OLD!) https://docs.unity3d.com/Packages/com.unity.tiny@0.13/manual/intro-for-unity-developers.html

Regl:
  https://github.com/regl-project/regl

e.g.
  https://github.com/jacklaplante/bowdown
  https://github.com/onegeek/webglu

Sketch fab:
  https://sketchfab.com

Defold:
  https://defold.com
    "I recall our unity engineer quite liked Defold, which had an 
    integrated builder tool, but for some reason the lead dev didnâ€™t 
    want to go with it." - https://news.ycombinator.com/item?id=24018097
  https://github.com/defold/defold
  Owned by King (Candy Crush, etc)

Google Docs switching to canvas:
  https://workspaceupdates.googleblog.com/2021/05/Google-Docs-Canvas-Based-Rendering-Update.html

Flutter does all UI via canvas:
  https://gallery.flutter.dev/#/

Construct:
  https://www.construct.net/en/make-games/showcase

WebGPU
    https://github.com/gpuweb/gpuweb
    status:
        https://github.com/gpuweb/gpuweb/wiki/Implementation-Status
    spec:
        https://gpuweb.github.io/gpuweb/
    examples:
      https://www.willusher.io/projects#WebGPU%20Experiments

Construct blog:
  https://www.construct.net/en/blogs/ashleys-blog-2/brief-history-graphics-web-1517
  https://www.construct.net/en/blogs/ashleys-blog-2/webgl-webgpu-construct-1519

Safari WebGPU intro:
  https://webkit.org/blog/9528/webgpu-and-wsl-in-safari/

Mozilla WebGPU intro:
  https://hacks.mozilla.org/2020/04/experimental-webgpu-in-firefox/

Chrome WebGPU intro:
  https://www.youtube.com/watch?v=K2JzIUIHIhc
  
TO DECIDE:
    Build our own renderer?

Understand URP:
    https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@12.0/manual/universalrp-builtin-feature-comparison.html'

GLTF viewers:
    https://sandbox.babylonjs.com/
    https://gltf-viewer.donmccurdy.com/
    https://gltf.insimo.com/
    https://github.khronos.org/glTF-Sample-Viewer-Release/
        https://github.com/KhronosGroup/glTF-Sample-Viewer

GLTF loader:
    https://github.com/mrdoob/three.js/blob/a98b9bf/examples/js/loaders/GLTFLoader.js

GLTF compression:
    https://google.github.io/draco/
        has JS encode / decode libraries

WebGPU on Chrome:
    https://developers.google.com/web/updates/2019/08/get-started-with-gpu-compute-on-the-web

WebGPU tutorials:
    https://alain.xyz/blog/raw-webgpu
        matrix library: https://github.com/toji/gl-matrix
    https://www.willusher.io/graphics/2020/06/15/0-to-gltf-triangle

WebGPU samples:
    https://github.com/mikbry/awesome-webgpu
    http://austin-eng.com/webgpu-samples/samples/computeBoids

Shaders Wow:
    Slime and ants: https://www.youtube.com/watch?v=X-iSQQgOd1A
    https://www.shadertoy.com

Game shaders for beginners:
  https://news.ycombinator.com/item?id=19895218
  https://github.com/lettier/3d-game-shaders-for-beginners
  https://www.youtube.com/watch?v=kfM-yu0iQBk

Ben Cloward on shaders:
  Shaders in Anthem:
    https://www.youtube.com/watch?v=IjQWRjWZGn0
  https://www.youtube.com/user/bcloward/videos?view=0&sort=p&flow=grid

Computer shader pathfinding:
  https://www.youtube.com/watch?v=1OSXWhd3hvI

TO LEARN COMPUTE SHADERS:
    Limitations ?
    From JS / WASM ?
    What can it be used for?
        Physics?
        Algorithms?
        Celular atomita?
        Procedural gen?
    101:
      https://news.ycombinator.com/item?id=27396634
      https://www.youtube.com/watch?v=DZRn_jNZjbw

Book of Shaders (online):
  https://thebookofshaders.com

Compute shader tutorial ($400?):
  https://paprika.studio/workshops/compute/

Shader School:
  https://github.com/stackgl/shader-school

SDFs (Signed Distance Field) ?
    https://joyrok.com/What-Are-SDFs-Anyway

Vulkan vs OpenGL:
    https://gamedev.stackexchange.com/questions/96014/what-is-vulkan-and-how-does-it-differ-from-opengl

WebGPU uses Web Shading Language (WSL)

webgpu-rs:
    https://github.com/gfx-rs/wgpu-rs
    Why WebGPU for native is good:
      http://kvark.github.io/web/gpu/native/2020/05/03/point-of-webgpu-native.html
    https://dawn.googlesource.com/dawn (webgpu on native by Google)

MIT computer graphics lectures:
    https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-837-computer-graphics-fall-2012/lecture-notes/
    lectures
      https://www.youtube.com/watch?v=-LqUu61oRdk&list=PLQ3UicqQtfNuBjzJ-KEWmG1yjiRMXYKhh
      https://www.youtube.com/watch?v=t7g2oaNs-c8&list=PLQ3UicqQtfNuKZjdA3fY1_X9gXn13JLlW

Game Engine Architecture book:
    https://www.gameenginebook.com/

RTX / ray tracing:
  minecraft RTX: https://alain.xyz/blog/frame-analysis-minecraftrtx
  on m1 https://www.willusher.io/graphics/2020/12/20/rt-dive-m1
    ~7-9 million rays / sec
  beyond ray-tracing http://sci.utah.edu/~will/papers/rtx-points-hpg19.pdf

pbr / physically based rendering:
  https://pbrt.org

GPU API concepts compared:
  https://alain.xyz/blog/comparison-of-modern-graphics-apis

Defered rendering:
  https://gamedev.stackexchange.com/questions/74/what-is-deferred-rendering
    Forward: O(geometry * lights)
    Defered: O(geometry + lights)
  Works poorly for transparency (most engines use Forward)
    see: depth peeling
  Uses large amounts of VRAM and frame buffer bandwidth
  stencil-based geometry vs "tiled/froxel compute-based shading"
  Unity: https://docs.unity3d.com/2021.2/Documentation/Manual/RenderTech-DeferredShading.html
  https://www.reddit.com/r/gamedev/comments/8klygv/is_deferred_shading_still_considered_state_of_the/
    "It looks like the industry is going towards a forward+/hybrid approach"
      0. Render Depth Prepass (optional, could prepare a thin gbuffer on this pass)
      1. Use depth buffer (or not) to bin lights into screenspace tiles, save this as a light buffer
      2. Render the geometry with the full shader, and get the light information from the screenspace coordinate, wich lets you see the lights on that tile
      3. Postprocess.
    "Forward+ splits the screen into a 2d grid and a process (compute or other shader) figures out what lights affect that tile. Forward++ takes this a step 
    further and instead of a 2d grid splitting the screen, its a 3d grid splitting space with perspective."
  used by Horizon Zero Dawn

Shadows:
  Shadow volumes? (aka stencil shadows)
    https://en.wikipedia.org/wiki/Shadow_volume
  Shadow maps

Lighting:
  pixel vs vertex
    could subdivide large triangles so vertex lighting is more accurate; no storage cost
    vertex + tessellation for particles (e.g. smoke):
      http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.699.187&rep=rep1&type=pdf
  Spherical Harmonics lighting
    https://computergraphics.stackexchange.com/questions/4164/what-are-spherical-harmonics-light-probes
    https://mynameismjp.wordpress.com/2016/10/09/sg-series-part-1-a-brief-and-incomplete-history-of-baked-lighting-representations/
  deferred vs forward
  https://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-shading/shading-normals
  WebGPU "clustered forward shading"
    https://toji.github.io/webgpu-clustered-shading/
    https://github.com/toji/webgpu-clustered-shading
      "I don't think WGSL has atomic methods yet so I can't effectively do the light list compacting 
      the way I want (or at least I don't know the workaround)."

TO LEARN:
  Fourier transform
    then Spherical Harmonics

GPU perf for artists:
  http://www.fragmentbuffer.com/gpu-performance-for-game-artists/
    https://news.ycombinator.com/item?id=14726355
    https://news.ycombinator.com/item?id=21978146

Frame analysis:
  RenderDoc:
    https://renderdoc.org
    https://spector.babylonjs.com (for WebGL)
  https://zhangdoa.com/posts/rendering-analysis-cyberpunk-2077
  https://alain.xyz/blog/frame-analysis-overwatch
  https://alain.xyz/blog/frame-analysis-mk11
  https://alain.xyz/blog/frame-analysis-minecraftrtx
  https://aschrein.github.io/2019/08/11/metro_breakdown.html
  https://aschrein.github.io/2019/08/01/re2_breakdown.html
  http://www.adriancourreges.com/blog/2016/09/09/doom-2016-graphics-study/
    https://news.ycombinator.com/item?id=12461896
    http://advances.realtimerendering.com/s2016/Siggraph2016_idTech6.pdf
  http://www.adriancourreges.com/blog/2017/12/15/mgs-v-graphics-study/
  http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/
    https://news.ycombinator.com/item?id=10492876
  http://www.adriancourreges.com/blog/2015/06/23/supreme-commander-graphics-study/
    https://news.ycombinator.com/item?id=9770020
  http://www.adriancourreges.com/blog/2015/03/10/deus-ex-human-revolution-graphics-study/
    https://news.ycombinator.com/item?id=9565891

BLOGS TO SCAN:
  https://www.ea.com/frostbite/news
  http://advances.realtimerendering.com/s2015/index.html (siggraph conference)
  https://simonschreibt.de/game-art-tricks/
  https://www.willusher.io
    lots of graphics projects: https://www.willusher.io/projects
    teapot rendering challenge https://graphics.cs.utah.edu/trc/
  https://www.cs.washington.edu/research/graphics
    https://grail.cs.washington.edu/research/
    http://courses.cs.washington.edu/courses/cse457/ Computer Graphics
    http://courses.cs.washington.edu/courses/cse458/ Computer Animation
    http://courses.cs.washington.edu/courses/csep557/ Trends in Computer Graphics
    http://courses.cs.washington.edu/courses/cse557/ Computer Graphics
  http://madebyevan.com

coloring models:
  https://www.willusher.io/webgl-ewa-splatter/#Dinosaur

TO READ:
  https://forum.beyond3d.com/threads/gpu-driven-rendering-siggraph-2015-follow-up.57240/
    "about GPU-driven rendering pipelines"

GDC:
  Horizon Zero Dawn:
    Vegitation https://www.youtube.com/watch?v=wavnKZNSYqU
    game design https://www.youtube.com/watch?v=TawhcWao9ls
    procedural gen https://www.youtube.com/watch?v=ToCozpl1sYY

Rust -> WebGPU examples:
  https://github.com/gfx-rs/wgpu-rs/tree/master/examples
  https://wgpu.rs

"Mixed resolution rendering":
  https://www.gdcvault.com/play/1022982/Mixed-Resolution-Rendering-in-Skylanders
    for clouds based on sprites
    downsample depth -> raster -> "bilateral" upsample 

"Mesh shaders":
  https://devblogs.microsoft.com/directx/dev-preview-of-new-directx-12-features/#directx-mesh-shader
  https://developer.nvidia.com/blog/introduction-turing-mesh-shaders/

"Geometry shaders":
  " are for creating new geometry on the fly. It's taking geometry of one type as input, and then 
  emitting a different number of the same, or another type of geoAmetry as output. You could have 
  points transformed to a series of triangles or quads."
    https://www.reddit.com/r/vulkan/comments/c9ws13/do_we_need_geometry_shader_anymore/
  http://www.joshbarczak.com/blog/?p=667 (they are slow)

  Maybe also a way of doing per-face data?
  https://docs.microsoft.com/en-us/previous-versions//bb205146(v=vs.85)?redirectedfrom=MSDN

  Don't use GS: https://twitter.com/pointinpolygon/status/1270695113967181827

LOD / automatic mesh simplification:
  quad simplification: https://www.youtube.com/watch?v=vBJcdClynFE

Rendering pipeline:
  https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview

Flat shading:
  "Provoking vertex" https://www.khronos.org/opengl/wiki/Primitive#Provoking_vertex
  "flat" interpolation qualifier https://www.khronos.org/opengl/wiki/Type_Qualifier_(GLSL)#Interpolation_qualifiers
  waiting on interplate(flat) support in Chrome's Tint WGSL parser:
    https://bugs.chromium.org/p/tint/issues/detail?id=746&q=interpolate&can=2
  https://gamedev.stackexchange.com/questions/154854/how-do-i-implement-flat-shading-in-glsl
    vec3 xTangent = dFdx( viewPosition );
    vec3 yTangent = dFdy( viewPosition );
    vec3 faceNormal = normalize( cross( xTangent, yTangent ) );

hierarchical /  models:
  https://sites.google.com/site/csc8820/educational/how-to-animate-hierarchical-models
  https://canvas.dartmouth.edu/courses/16840/assignments/82764

how many triangles?
  "overwatch ingame characters has 60K tris"

"bundles"?
  https://computergraphics.stackexchange.com/questions/4066/whats-the-main-difference-of-pipeline-process-between-vulkan-and-dx12

Why r draw calls expensive?
  "because if you send too little to the GPU, you're CPU bound and the GPU idles"
  https://stackoverflow.com/questions/4853856/why-are-draw-calls-expensive
  https://www.nvidia.com/docs/IO/8228/BatchBatchBatch.pdf

Data per triangle:
  "instanced vertex attributes"
  gl_PrimitiveID
  "texture buffer object (TBO)" for high primitive count
    texelFetch

Graphics storage options:
  Vertex buffer
  Vertex buffer (instance step)
  Uniform buffer
    Small, performant
  SSBOS
    large, slow, writable

Unreal 5 analysis:
  https://www.elopezr.com/a-macro-view-of-nanite/

Flat shading in PlayCanvas:
  https://omar-shehata.medium.com/flat-shading-in-webgl-with-playcanvas-a-quick-tip-97d1bd85258f

Camera transformations:
  https://www.3dgep.com/understanding-the-view-matrix/#Transformations
  http://www.codinglabs.net/article_world_view_projection_matrix.aspx
  https://gamedev.stackexchange.com/questions/178643/the-view-matrix-finally-explained
  https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix
  http://web.cse.ohio-state.edu/~wang.3602/courses/cse5542-2013-spring/6-Transformation_II.pdf
  https://learnopengl.com/Getting-started/Coordinate-Systems

hierarchical modeling:
  https://www.youtube.com/watch?v=JdhpViedm0g&list=PLQ3UicqQtfNuBjzJ-KEWmG1yjiRMXYKhh&index=5

Low-poly planet map effect:
  https://www.youtube.com/watch?v=i5zwDoYXH5c

WebGPU vs WebGL:
  https://www.babylonjs.com/demos/webgpu/forestwebgl
  https://www.babylonjs.com/demos/webgpu/forestwebgpu

Alpha tested vs transparency:
  https://forum.unity.com/threads/difference-between-alphatest-and-transparent-renderqueue.458750/
  alpha tested renders front-to-back (occluded pixels r ignored)
  transparency renders back-to-front

Texture compression:
  BC7, BC4, BCn
  https://www.reedbeta.com/blog/understanding-bcn-texture-compression-formats/

Foveated rendering:
  https://en.wikipedia.org/wiki/Foveated_rendering

GPU hardware:
  Rasterization is still done in fixed hardware, not programmable
    https://en.wikipedia.org/wiki/Rasterisation
    (Intel tried with Larrabee, aborted)
    (Nvidia tried: https://highperformancegraphics.net/previous/www_2011/media/Papers/HPG2011_Papers_Laine.pdf, 
      https://dl.acm.org/doi/10.1145/2018323.2018337, http://code.google.com/p/cudaraster/)
      Issues: interpolation, anti-aliasing, power consumption
    Desire for software rasterization:
      shader perf boost?
      ROP (render output unit): a-buffering, order-independent transparency
      Stochastic rasterization
      Non-linear rasterization
  Vertex and fragment shaders
  Compute vs Fragment for post-processing:
    https://computergraphics.stackexchange.com/questions/54/when-is-a-compute-shader-more-efficient-than-a-pixel-shader-for-image-filtering
  ROP:
    https://en.wikipedia.org/wiki/Render_output_unit
    handles anti-aliasing (e.g. MSAA)

Z-order curve:
  https://en.wikipedia.org/wiki/Z-order_curve#Applications
  Zig-zag textures for more efficient cache locality

Albedo vs Diffuse:
  https://computergraphics.stackexchange.com/questions/350/albedo-vs-diffuse

Virtual texturing:
  http://holger.dammertz.org/stuff/notes_VirtualTexturing.html
  https://computergraphics.stackexchange.com/questions/1768/how-can-virtual-texturing-actually-be-efficient

GPU memory access costs:
  https://computergraphics.stackexchange.com/questions/37/what-is-the-cost-of-changing-state
    TODO: read for good GPU perf tips
  most to least expensive state changes:
    render target (~60K/s)
    program (~300K/s)
    ROP
    texture bindings (~1.5M/s)
    vertex format
    UBO bindings
    vertex bindings
    uniform updates (~10M/s)

Don't have T junctions in meshes:
  https://computergraphics.stackexchange.com/questions/1461/why-do-t-junctions-in-meshes-result-in-cracks